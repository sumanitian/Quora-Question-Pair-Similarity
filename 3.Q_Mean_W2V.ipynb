{"cells":[{"cell_type":"markdown","metadata":{"id":"MRP-fAQedMTd"},"source":["<h2> 3.6 Featurizing text data with tfidf weighted word-vectors </h2>"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1105,"status":"ok","timestamp":1644585091097,"user":{"displayName":"Applied AI Course","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSpfk3evOnQu4WaAr65Jsk94o0T_MicRlfD3-hAVs=s64","userId":"06629147635963609455"},"user_tz":-330},"id":"-3IbomL8dMTi"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","import time\n","import warnings\n","import numpy as np\n","from nltk.corpus import stopwords\n","from sklearn.preprocessing import normalize\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","warnings.filterwarnings(\"ignore\")\n","import sys\n","import os \n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","\n","# exctract word2vec vectors\n","# https://github.com/explosion/spaCy/issues/1721\n","# http://landinghub.visualstudio.com/visual-cpp-build-tools\n","import spacy"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"j5XNgVyLdMT7"},"outputs":[],"source":["# avoid decoding problems\n","df = pd.read_csv(\"train.csv\")\n","df['question1'] = df['question1'].apply(lambda x: str(x))\n","df['question2'] = df['question2'].apply(lambda x: str(x))"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"HbiMFpgRdMUJ","outputId":"21c00698-7f2a-4ce4-e665-f7a2feaab6fa"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n","      <td>What would happen if the Indian government sto...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>How can I increase the speed of my internet co...</td>\n","      <td>How can Internet speed be increased by hacking...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>Why am I mentally very lonely? How can I solve...</td>\n","      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>Which one dissolve in water quikly sugar, salt...</td>\n","      <td>Which fish would survive in salt water?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  qid1  qid2                                          question1  \\\n","0   0     1     2  What is the step by step guide to invest in sh...   \n","1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n","2   2     5     6  How can I increase the speed of my internet co...   \n","3   3     7     8  Why am I mentally very lonely? How can I solve...   \n","4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n","\n","                                           question2  is_duplicate  \n","0  What is the step by step guide to invest in sh...             0  \n","1  What would happen if the Indian government sto...             0  \n","2  How can Internet speed be increased by hacking...             0  \n","3  Find the remainder when [math]23^{24}[/math] i...             0  \n","4            Which fish would survive in salt water?             0  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"RU3HqJXwdMUj"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","# merge texts\n","questions = list(df['question1']) + list(df['question2'])\n","\n","tfidf = TfidfVectorizer(lowercase=False, )\n","tfidf.fit_transform(questions)\n","\n","# dict key:word and value:tf-idf score\n","word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"2JKI2yT4dMUv"},"source":["- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores.\n","- here we use a pre-trained GLOVE model which comes free with \"Spacy\".  https://spacy.io/usage/vectors-similarity\n","- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":108164,"status":"ok","timestamp":1644584896974,"user":{"displayName":"Applied AI Course","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSpfk3evOnQu4WaAr65Jsk94o0T_MicRlfD3-hAVs=s64","userId":"06629147635963609455"},"user_tz":-330},"id":"sGpwzISi3pyU","outputId":"102981e6-82cf-4b75-8017-ff12b094ad3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting en-core-web-lg==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n","     -----                                 84.2/587.7 MB 253.6 kB/s eta 0:33:06\n"]},{"name":"stderr","output_type":"stream","text":["2023-04-14 09:51:50.781669: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2023-04-14 09:51:50.781887: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","2023-04-14 09:51:52.640730: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll\n","2023-04-14 09:51:52.655800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n","pciBusID: 0000:01:00.0 name: NVIDIA GeForce MX450 computeCapability: 7.5\n","coreClock: 1.275GHz coreCount: 14 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 52.17GiB/s\n","2023-04-14 09:51:52.656695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2023-04-14 09:51:52.657328: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n","2023-04-14 09:51:52.658103: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n","2023-04-14 09:51:52.659308: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n","2023-04-14 09:51:52.660547: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n","2023-04-14 09:51:52.661344: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found\n","2023-04-14 09:51:52.662080: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n","2023-04-14 09:51:52.662718: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n","2023-04-14 09:51:52.662871: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","ERROR: Exception:\n","Traceback (most recent call last):\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 437, in _error_catcher\n","    yield\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 560, in read\n","    data = self._fp_read(amt) if not fp_closed else b\"\"\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 526, in _fp_read\n","    return self._fp.read(amt) if amt is not None else self._fp.read()\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 90, in read\n","    data = self.__fp.read(amt)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\", line 459, in read\n","    n = self.readinto(b)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\", line 503, in readinto\n","    n = self.fp.readinto(b)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\socket.py\", line 704, in readinto\n","    return self._sock.recv_into(b)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py\", line 1241, in recv_into\n","    return self.read(nbytes, buffer)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py\", line 1099, in read\n","    return self._sslobj.read(len, buffer)\n","socket.timeout: The read operation timed out\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 160, in exc_logging_wrapper\n","    status = run_func(*args)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 247, in wrapper\n","    return func(self, options, args)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 400, in run\n","    requirement_set = resolver.resolve(\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 73, in resolve\n","    collected = self.factory.collect_root_requirements(root_reqs)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 491, in collect_root_requirements\n","    req = self._make_requirement_from_install_req(\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 453, in _make_requirement_from_install_req\n","    cand = self._make_candidate_from_link(\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 206, in _make_candidate_from_link\n","    self._link_candidate_cache[link] = LinkCandidate(\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 297, in __init__\n","    super().__init__(\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 162, in __init__\n","    self.dist = self._prepare()\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 231, in _prepare\n","    dist = self._prepare_distribution()\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 308, in _prepare_distribution\n","    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 491, in prepare_linked_requirement\n","    return self._prepare_linked_requirement(req, parallel_builds)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 536, in _prepare_linked_requirement\n","    local_file = unpack_url(\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 166, in unpack_url\n","    file = get_http_url(\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 107, in get_http_url\n","    from_path, content_type = download(link, temp_dir.path)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 147, in __call__\n","    for chunk in chunks:\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 53, in _rich_progress_bar\n","    for chunk in iterable:\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n","    for chunk in response.raw.stream(\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 621, in stream\n","    data = self.read(amt=amt, decode_content=decode_content)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 586, in read\n","    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\contextlib.py\", line 135, in __exit__\n","    self.gen.throw(type, value, traceback)\n","  File \"c:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 442, in _error_catcher\n","    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n","pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='objects.githubusercontent.com', port=443): Read timed out.\n","\n","[notice] A new release of pip available: 22.3.1 -> 23.0.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n","full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n","Collecting en-core-web-sm==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n","     -------------------------------------- 12.8/12.8 MB 159.0 kB/s eta 0:00:00\n","Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n","Requirement already satisfied: setuptools in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (56.0.0)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n","Requirement already satisfied: jinja2 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.9.2)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n","Requirement already satisfied: pathy>=0.10.0 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.0.0)\n","Requirement already satisfied: numpy>=1.15.0 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.19.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.7.4.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.9)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.5.18.1)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n","Requirement already satisfied: colorama in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\suman\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n","Installing collected packages: en-core-web-sm\n","Successfully installed en-core-web-sm-3.5.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"]},{"name":"stderr","output_type":"stream","text":["2023-04-14 09:57:57.369460: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2023-04-14 09:57:57.369682: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","2023-04-14 09:57:59.078579: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll\n","2023-04-14 09:57:59.092782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n","pciBusID: 0000:01:00.0 name: NVIDIA GeForce MX450 computeCapability: 7.5\n","coreClock: 1.275GHz coreCount: 14 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 52.17GiB/s\n","2023-04-14 09:57:59.094230: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2023-04-14 09:57:59.094982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n","2023-04-14 09:57:59.095643: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n","2023-04-14 09:57:59.096327: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n","2023-04-14 09:57:59.096947: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n","2023-04-14 09:57:59.097553: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found\n","2023-04-14 09:57:59.098170: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n","2023-04-14 09:57:59.098905: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n","2023-04-14 09:57:59.099121: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000020BEB255370>, 'Connection to github.com timed out. (connect timeout=15)')': /explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl\n","\n","[notice] A new release of pip available: 22.3.1 -> 23.0.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!python -m spacy download en_core_web_lg\n","# !python -m spacy download en_core_web_sm\n","# !python -m spacy download en_core_web_md\n","!python -m spacy download en"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23761,"status":"ok","timestamp":1644585114855,"user":{"displayName":"Applied AI Course","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSpfk3evOnQu4WaAr65Jsk94o0T_MicRlfD3-hAVs=s64","userId":"06629147635963609455"},"user_tz":-330},"id":"PFS6m8z5dMUz","outputId":"c166e549-80be-4a79-95e3-9ea65a191971"},"outputs":[{"ename":"OSError","evalue":"[E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[1;32mc:\\Users\\suman\\Desktop\\Quora-Question Pair similarity\\3.Q_Mean_W2V.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# en_vectors_web_lg, which includes over 1 million unique vectors.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39men_core_web_lg\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# vecs1 = []\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# # https://github.com/noamraph/tqdm\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# # tqdm is used to print the progrss bar\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m#     vecs1.append(mean_vec1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# df['q1_feats_m'] = list(vecs1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m x\u001b[39m=\u001b[39mnlp(\u001b[39m'\u001b[39m\u001b[39mman\u001b[39m\u001b[39m'\u001b[39m)\n","File \u001b[1;32mc:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m     \u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m     55\u001b[0m         name,\n\u001b[0;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m     61\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\suman\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\util.py:449\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n","\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory."]}],"source":["# en_vectors_web_lg, which includes over 1 million unique vectors.\n","nlp = spacy.load('en_core_web_lg')\n","# vecs1 = []\n","# # https://github.com/noamraph/tqdm\n","# # tqdm is used to print the progrss bar\n","# for qu1 in tqdm(list(df['question1'])):\n","#     doc1 = nlp(qu1) \n","#     # 384 is the number of dimensions of vectors \n","#     mean_vec1 = np.zeros([len(doc1), len(doc1[0].vector)])\n","#     for word1 in doc1:\n","#         # word2vec\n","#         vec1 = word1.vector\n","#         # fetch df score\n","#         try:\n","#             idf = word2tfidf[str(word1)]\n","#         except:\n","#             idf = 0\n","#         # compute final vec\n","#         mean_vec1 += vec1 * idf\n","#     mean_vec1 = mean_vec1.mean(axis=0)\n","#     vecs1.append(mean_vec1)\n","# df['q1_feats_m'] = list(vecs1)\n","x=nlp('man')\n","len(x.vector)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"62GEF-RbdMVB","outputId":"60a4f5f8-5582-4886-befd-2ab6ed99c753"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/404290 [00:00<?, ?it/s]\n"]},{"ename":"NameError","evalue":"name 'nlp' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\suman\\Desktop\\Quora-Question Pair similarity\\3.Q_Mean_W2V.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vecs2 \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m qu2 \u001b[39min\u001b[39;00m tqdm(\u001b[39mlist\u001b[39m(df[\u001b[39m'\u001b[39m\u001b[39mquestion2\u001b[39m\u001b[39m'\u001b[39m])):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     doc2 \u001b[39m=\u001b[39m nlp(qu2) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     mean_vec1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros([\u001b[39mlen\u001b[39m(doc1), \u001b[39mlen\u001b[39m(doc2[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvector)])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m word2 \u001b[39min\u001b[39;00m doc2:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/suman/Desktop/Quora-Question%20Pair%20similarity/3.Q_Mean_W2V.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39m# word2vec\u001b[39;00m\n","\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"]}],"source":["vecs2 = []\n","for qu2 in tqdm(list(df['question2'])):\n","    doc2 = nlp(qu2) \n","    mean_vec1 = np.zeros([len(doc1), len(doc2[0].vector)])\n","    for word2 in doc2:\n","        # word2vec\n","        vec2 = word2.vector\n","        # fetch df score\n","        try:\n","            idf = word2tfidf[str(word2)]\n","        except:\n","            #print word\n","            idf = 0\n","        # compute final vec\n","        mean_vec2 += vec2 * idf\n","    mean_vec2 = mean_vec2.mean(axis=0)\n","    vecs2.append(mean_vec2)\n","df['q2_feats_m'] = list(vecs2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a38GBlGWdMVQ"},"outputs":[],"source":["#prepro_features_train.csv (Simple Preprocessing Feartures)\n","#nlp_features_train.csv (NLP Features)\n","if os.path.isfile('nlp_features_train.csv'):\n","    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n","else:\n","    print(\"download nlp_features_train.csv from drive or run previous notebook\")\n","\n","if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n","    dfppro = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n","else:\n","    print(\"download df_fe_without_preprocessing_train.csv from drive or run previous notebook\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"apdRa1kndMVb"},"outputs":[],"source":["df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n","df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n","df3 = df.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n","df3_q1 = pd.DataFrame(df3.q1_feats_m.values.tolist(), index= df3.index)\n","df3_q2 = pd.DataFrame(df3.q2_feats_m.values.tolist(), index= df3.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xzWAqGegdMVp","outputId":"2f88eeda-244f-4bbb-a51c-a8680fe8fb92"},"outputs":[{"data":{"text/html":["<div>\n","<style>\n","    .dataframe thead tr:only-child th {\n","        text-align: right;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: left;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>is_duplicate</th>\n","      <th>cwc_min</th>\n","      <th>cwc_max</th>\n","      <th>csc_min</th>\n","      <th>csc_max</th>\n","      <th>ctc_min</th>\n","      <th>ctc_max</th>\n","      <th>last_word_eq</th>\n","      <th>first_word_eq</th>\n","      <th>abs_len_diff</th>\n","      <th>mean_len</th>\n","      <th>token_set_ratio</th>\n","      <th>token_sort_ratio</th>\n","      <th>fuzz_ratio</th>\n","      <th>fuzz_partial_ratio</th>\n","      <th>longest_substr_ratio</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.999980</td>\n","      <td>0.833319</td>\n","      <td>0.999983</td>\n","      <td>0.999983</td>\n","      <td>0.916659</td>\n","      <td>0.785709</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>13.0</td>\n","      <td>100</td>\n","      <td>93</td>\n","      <td>93</td>\n","      <td>100</td>\n","      <td>0.982759</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.799984</td>\n","      <td>0.399996</td>\n","      <td>0.749981</td>\n","      <td>0.599988</td>\n","      <td>0.699993</td>\n","      <td>0.466664</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>12.5</td>\n","      <td>86</td>\n","      <td>63</td>\n","      <td>66</td>\n","      <td>75</td>\n","      <td>0.596154</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0.399992</td>\n","      <td>0.333328</td>\n","      <td>0.399992</td>\n","      <td>0.249997</td>\n","      <td>0.399996</td>\n","      <td>0.285712</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>12.0</td>\n","      <td>66</td>\n","      <td>66</td>\n","      <td>54</td>\n","      <td>54</td>\n","      <td>0.166667</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>12.0</td>\n","      <td>36</td>\n","      <td>36</td>\n","      <td>35</td>\n","      <td>40</td>\n","      <td>0.039216</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0.399992</td>\n","      <td>0.199998</td>\n","      <td>0.999950</td>\n","      <td>0.666644</td>\n","      <td>0.571420</td>\n","      <td>0.307690</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>6.0</td>\n","      <td>10.0</td>\n","      <td>67</td>\n","      <td>47</td>\n","      <td>46</td>\n","      <td>56</td>\n","      <td>0.175000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n","0   0             0  0.999980  0.833319  0.999983  0.999983  0.916659   \n","1   1             0  0.799984  0.399996  0.749981  0.599988  0.699993   \n","2   2             0  0.399992  0.333328  0.399992  0.249997  0.399996   \n","3   3             0  0.000000  0.000000  0.000000  0.000000  0.000000   \n","4   4             0  0.399992  0.199998  0.999950  0.666644  0.571420   \n","\n","    ctc_max  last_word_eq  first_word_eq  abs_len_diff  mean_len  \\\n","0  0.785709           0.0            1.0           2.0      13.0   \n","1  0.466664           0.0            1.0           5.0      12.5   \n","2  0.285712           0.0            1.0           4.0      12.0   \n","3  0.000000           0.0            0.0           2.0      12.0   \n","4  0.307690           0.0            1.0           6.0      10.0   \n","\n","   token_set_ratio  token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  \\\n","0              100                93          93                 100   \n","1               86                63          66                  75   \n","2               66                66          54                  54   \n","3               36                36          35                  40   \n","4               67                47          46                  56   \n","\n","   longest_substr_ratio  \n","0              0.982759  \n","1              0.596154  \n","2              0.166667  \n","3              0.039216  \n","4              0.175000  "]},"execution_count":9,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# dataframe of nlp features\n","df1.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4DQnDtndMV4","outputId":"2e288eed-e8fa-4ec3-a9b9-4e4daba52fc1"},"outputs":[{"data":{"text/html":["<div>\n","<style>\n","    .dataframe thead tr:only-child th {\n","        text-align: right;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: left;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>freq_qid1</th>\n","      <th>freq_qid2</th>\n","      <th>q1len</th>\n","      <th>q2len</th>\n","      <th>q1_n_words</th>\n","      <th>q2_n_words</th>\n","      <th>word_Common</th>\n","      <th>word_Total</th>\n","      <th>word_share</th>\n","      <th>freq_q1+q2</th>\n","      <th>freq_q1-q2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>66</td>\n","      <td>57</td>\n","      <td>14</td>\n","      <td>12</td>\n","      <td>10.0</td>\n","      <td>23.0</td>\n","      <td>0.434783</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>51</td>\n","      <td>88</td>\n","      <td>8</td>\n","      <td>13</td>\n","      <td>4.0</td>\n","      <td>20.0</td>\n","      <td>0.200000</td>\n","      <td>5</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>73</td>\n","      <td>59</td>\n","      <td>14</td>\n","      <td>10</td>\n","      <td>4.0</td>\n","      <td>24.0</td>\n","      <td>0.166667</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>50</td>\n","      <td>65</td>\n","      <td>11</td>\n","      <td>9</td>\n","      <td>0.0</td>\n","      <td>19.0</td>\n","      <td>0.000000</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>76</td>\n","      <td>39</td>\n","      <td>13</td>\n","      <td>7</td>\n","      <td>2.0</td>\n","      <td>20.0</td>\n","      <td>0.100000</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  freq_qid1  freq_qid2  q1len  q2len  q1_n_words  q2_n_words  \\\n","0   0          1          1     66     57          14          12   \n","1   1          4          1     51     88           8          13   \n","2   2          1          1     73     59          14          10   \n","3   3          1          1     50     65          11           9   \n","4   4          3          1     76     39          13           7   \n","\n","   word_Common  word_Total  word_share  freq_q1+q2  freq_q1-q2  \n","0         10.0        23.0    0.434783           2           0  \n","1          4.0        20.0    0.200000           5           3  \n","2          4.0        24.0    0.166667           2           0  \n","3          0.0        19.0    0.000000           2           0  \n","4          2.0        20.0    0.100000           4           2  "]},"execution_count":10,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# data before preprocessing \n","df2.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_1YIPtTwdMWC","outputId":"510f4c73-0706-4633-d706-e0d348ebfa71"},"outputs":[{"data":{"text/html":["<div>\n","<style>\n","    .dataframe thead tr:only-child th {\n","        text-align: right;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: left;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>374</th>\n","      <th>375</th>\n","      <th>376</th>\n","      <th>377</th>\n","      <th>378</th>\n","      <th>379</th>\n","      <th>380</th>\n","      <th>381</th>\n","      <th>382</th>\n","      <th>383</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>121.929927</td>\n","      <td>100.083900</td>\n","      <td>72.497894</td>\n","      <td>115.641800</td>\n","      <td>-48.370870</td>\n","      <td>34.619058</td>\n","      <td>-172.057787</td>\n","      <td>-92.502617</td>\n","      <td>113.223315</td>\n","      <td>50.562441</td>\n","      <td>...</td>\n","      <td>12.397642</td>\n","      <td>40.909519</td>\n","      <td>8.150261</td>\n","      <td>-15.170692</td>\n","      <td>18.007709</td>\n","      <td>6.166999</td>\n","      <td>-30.124163</td>\n","      <td>3.700902</td>\n","      <td>-1.757693</td>\n","      <td>-1.818058</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-78.070939</td>\n","      <td>54.843781</td>\n","      <td>82.738482</td>\n","      <td>98.191872</td>\n","      <td>-51.234859</td>\n","      <td>55.013510</td>\n","      <td>-39.140730</td>\n","      <td>-82.692352</td>\n","      <td>45.161489</td>\n","      <td>-9.556289</td>\n","      <td>...</td>\n","      <td>-21.987077</td>\n","      <td>-12.389279</td>\n","      <td>20.667979</td>\n","      <td>2.202714</td>\n","      <td>-17.142454</td>\n","      <td>-5.880972</td>\n","      <td>-10.123963</td>\n","      <td>-4.890663</td>\n","      <td>-13.018389</td>\n","      <td>-5.219310</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-5.355015</td>\n","      <td>73.671810</td>\n","      <td>14.376365</td>\n","      <td>104.130241</td>\n","      <td>1.433537</td>\n","      <td>35.229116</td>\n","      <td>-148.519385</td>\n","      <td>-97.124595</td>\n","      <td>41.972195</td>\n","      <td>50.948731</td>\n","      <td>...</td>\n","      <td>3.027700</td>\n","      <td>14.025767</td>\n","      <td>-2.960312</td>\n","      <td>-3.206544</td>\n","      <td>4.355141</td>\n","      <td>2.936152</td>\n","      <td>-20.199555</td>\n","      <td>9.816351</td>\n","      <td>11.894366</td>\n","      <td>-8.798819</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5.778359</td>\n","      <td>-34.712038</td>\n","      <td>48.999631</td>\n","      <td>59.699204</td>\n","      <td>40.661263</td>\n","      <td>-41.658731</td>\n","      <td>-36.808594</td>\n","      <td>24.170655</td>\n","      <td>0.235600</td>\n","      <td>-29.407290</td>\n","      <td>...</td>\n","      <td>13.100007</td>\n","      <td>1.405670</td>\n","      <td>-1.891076</td>\n","      <td>-7.882638</td>\n","      <td>18.000561</td>\n","      <td>12.106918</td>\n","      <td>-10.507835</td>\n","      <td>5.243834</td>\n","      <td>10.158340</td>\n","      <td>5.886351</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>51.138220</td>\n","      <td>38.587312</td>\n","      <td>123.639488</td>\n","      <td>53.333041</td>\n","      <td>-47.062739</td>\n","      <td>37.356212</td>\n","      <td>-298.722753</td>\n","      <td>-106.421119</td>\n","      <td>106.248914</td>\n","      <td>65.880707</td>\n","      <td>...</td>\n","      <td>13.906532</td>\n","      <td>43.461721</td>\n","      <td>11.519207</td>\n","      <td>-22.468284</td>\n","      <td>45.431128</td>\n","      <td>8.161224</td>\n","      <td>-35.373910</td>\n","      <td>7.728865</td>\n","      <td>9.592849</td>\n","      <td>5.447336</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 384 columns</p>\n","</div>"],"text/plain":["          0           1           2           3          4          5    \\\n","0  121.929927  100.083900   72.497894  115.641800 -48.370870  34.619058   \n","1  -78.070939   54.843781   82.738482   98.191872 -51.234859  55.013510   \n","2   -5.355015   73.671810   14.376365  104.130241   1.433537  35.229116   \n","3    5.778359  -34.712038   48.999631   59.699204  40.661263 -41.658731   \n","4   51.138220   38.587312  123.639488   53.333041 -47.062739  37.356212   \n","\n","          6           7           8          9      ...           374  \\\n","0 -172.057787  -92.502617  113.223315  50.562441    ...     12.397642   \n","1  -39.140730  -82.692352   45.161489  -9.556289    ...    -21.987077   \n","2 -148.519385  -97.124595   41.972195  50.948731    ...      3.027700   \n","3  -36.808594   24.170655    0.235600 -29.407290    ...     13.100007   \n","4 -298.722753 -106.421119  106.248914  65.880707    ...     13.906532   \n","\n","         375        376        377        378        379        380       381  \\\n","0  40.909519   8.150261 -15.170692  18.007709   6.166999 -30.124163  3.700902   \n","1 -12.389279  20.667979   2.202714 -17.142454  -5.880972 -10.123963 -4.890663   \n","2  14.025767  -2.960312  -3.206544   4.355141   2.936152 -20.199555  9.816351   \n","3   1.405670  -1.891076  -7.882638  18.000561  12.106918 -10.507835  5.243834   \n","4  43.461721  11.519207 -22.468284  45.431128   8.161224 -35.373910  7.728865   \n","\n","         382       383  \n","0  -1.757693 -1.818058  \n","1 -13.018389 -5.219310  \n","2  11.894366 -8.798819  \n","3  10.158340  5.886351  \n","4   9.592849  5.447336  \n","\n","[5 rows x 384 columns]"]},"execution_count":11,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# Questions 1 tfidf weighted word2vec\n","df3_q1.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wUMdkJTNdMWL","outputId":"69e3e256-cbb8-4fe2-aaf2-9088c3868b29"},"outputs":[{"data":{"text/html":["<div>\n","<style>\n","    .dataframe thead tr:only-child th {\n","        text-align: right;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: left;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>374</th>\n","      <th>375</th>\n","      <th>376</th>\n","      <th>377</th>\n","      <th>378</th>\n","      <th>379</th>\n","      <th>380</th>\n","      <th>381</th>\n","      <th>382</th>\n","      <th>383</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>125.983301</td>\n","      <td>95.636485</td>\n","      <td>42.114702</td>\n","      <td>95.449980</td>\n","      <td>-37.386295</td>\n","      <td>39.400078</td>\n","      <td>-148.116070</td>\n","      <td>-87.851475</td>\n","      <td>110.371966</td>\n","      <td>62.272814</td>\n","      <td>...</td>\n","      <td>16.165592</td>\n","      <td>33.030668</td>\n","      <td>7.019996</td>\n","      <td>-14.793959</td>\n","      <td>15.437511</td>\n","      <td>8.199658</td>\n","      <td>-25.070834</td>\n","      <td>1.571619</td>\n","      <td>1.603738</td>\n","      <td>0.305645</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-106.871904</td>\n","      <td>80.290331</td>\n","      <td>79.066297</td>\n","      <td>59.302092</td>\n","      <td>-42.175328</td>\n","      <td>117.616655</td>\n","      <td>-144.364237</td>\n","      <td>-127.131513</td>\n","      <td>22.962533</td>\n","      <td>25.397575</td>\n","      <td>...</td>\n","      <td>-4.901128</td>\n","      <td>-4.565393</td>\n","      <td>41.520751</td>\n","      <td>-0.727564</td>\n","      <td>-16.413776</td>\n","      <td>-7.373778</td>\n","      <td>2.638877</td>\n","      <td>-7.403457</td>\n","      <td>2.703070</td>\n","      <td>0.408040</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7.072875</td>\n","      <td>15.513378</td>\n","      <td>1.846914</td>\n","      <td>85.937583</td>\n","      <td>-33.808811</td>\n","      <td>94.702337</td>\n","      <td>-122.256856</td>\n","      <td>-114.009530</td>\n","      <td>53.922293</td>\n","      <td>60.131814</td>\n","      <td>...</td>\n","      <td>8.359966</td>\n","      <td>-2.165985</td>\n","      <td>10.936580</td>\n","      <td>-16.531660</td>\n","      <td>14.681230</td>\n","      <td>15.633759</td>\n","      <td>-1.210901</td>\n","      <td>14.183826</td>\n","      <td>11.703135</td>\n","      <td>10.148075</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>39.421531</td>\n","      <td>44.136989</td>\n","      <td>-24.010929</td>\n","      <td>85.265863</td>\n","      <td>-0.339022</td>\n","      <td>-9.323137</td>\n","      <td>-60.499651</td>\n","      <td>-37.044763</td>\n","      <td>49.407848</td>\n","      <td>-23.350150</td>\n","      <td>...</td>\n","      <td>3.311411</td>\n","      <td>3.788879</td>\n","      <td>13.398598</td>\n","      <td>-6.592596</td>\n","      <td>6.437365</td>\n","      <td>5.993293</td>\n","      <td>2.732392</td>\n","      <td>-3.727647</td>\n","      <td>5.614115</td>\n","      <td>6.023693</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>31.950101</td>\n","      <td>62.854106</td>\n","      <td>1.778164</td>\n","      <td>36.218768</td>\n","      <td>-45.130875</td>\n","      <td>66.674880</td>\n","      <td>-106.342341</td>\n","      <td>-22.901008</td>\n","      <td>59.835938</td>\n","      <td>62.663961</td>\n","      <td>...</td>\n","      <td>-2.403870</td>\n","      <td>11.991204</td>\n","      <td>8.088483</td>\n","      <td>-15.090201</td>\n","      <td>8.375166</td>\n","      <td>1.727225</td>\n","      <td>-6.601129</td>\n","      <td>11.317413</td>\n","      <td>11.544603</td>\n","      <td>2.478689</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 384 columns</p>\n","</div>"],"text/plain":["          0          1          2          3          4           5    \\\n","0  125.983301  95.636485  42.114702  95.449980 -37.386295   39.400078   \n","1 -106.871904  80.290331  79.066297  59.302092 -42.175328  117.616655   \n","2    7.072875  15.513378   1.846914  85.937583 -33.808811   94.702337   \n","3   39.421531  44.136989 -24.010929  85.265863  -0.339022   -9.323137   \n","4   31.950101  62.854106   1.778164  36.218768 -45.130875   66.674880   \n","\n","          6           7           8          9      ...            374  \\\n","0 -148.116070  -87.851475  110.371966  62.272814    ...      16.165592   \n","1 -144.364237 -127.131513   22.962533  25.397575    ...      -4.901128   \n","2 -122.256856 -114.009530   53.922293  60.131814    ...       8.359966   \n","3  -60.499651  -37.044763   49.407848 -23.350150    ...       3.311411   \n","4 -106.342341  -22.901008   59.835938  62.663961    ...      -2.403870   \n","\n","         375        376        377        378        379        380  \\\n","0  33.030668   7.019996 -14.793959  15.437511   8.199658 -25.070834   \n","1  -4.565393  41.520751  -0.727564 -16.413776  -7.373778   2.638877   \n","2  -2.165985  10.936580 -16.531660  14.681230  15.633759  -1.210901   \n","3   3.788879  13.398598  -6.592596   6.437365   5.993293   2.732392   \n","4  11.991204   8.088483 -15.090201   8.375166   1.727225  -6.601129   \n","\n","         381        382        383  \n","0   1.571619   1.603738   0.305645  \n","1  -7.403457   2.703070   0.408040  \n","2  14.183826  11.703135  10.148075  \n","3  -3.727647   5.614115   6.023693  \n","4  11.317413  11.544603   2.478689  \n","\n","[5 rows x 384 columns]"]},"execution_count":12,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# Questions 2 tfidf weighted word2vec\n","df3_q2.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ozz83vh4dMWU","outputId":"e5b30f77-2849-4b08-9949-0912ec0db418"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of features in nlp dataframe : 17\n","Number of features in preprocessed dataframe : 12\n","Number of features in question1 w2v  dataframe : 384\n","Number of features in question2 w2v  dataframe : 384\n","Number of features in final dataframe  : 794\n"]}],"source":["print(\"Number of features in nlp dataframe :\", df1.shape[1])\n","print(\"Number of features in preprocessed dataframe :\", df2.shape[1])\n","print(\"Number of features in question1 w2v  dataframe :\", df3_q1.shape[1])\n","print(\"Number of features in question2 w2v  dataframe :\", df3_q2.shape[1])\n","print(\"Number of features in final dataframe  :\", df1.shape[1]+df2.shape[1]+df3_q1.shape[1]+df3_q2.shape[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HmfZ5Q1zdMWl"},"outputs":[],"source":["# storing the final features to csv file\n","if not os.path.isfile('final_features.csv'):\n","    df3_q1['id']=df1['id']\n","    df3_q2['id']=df1['id']\n","    df1  = df1.merge(df2, on='id',how='left')\n","    df2  = df3_q1.merge(df3_q2, on='id',how='left')\n","    result  = df1.merge(df2, on='id',how='left')\n","    result.to_csv('final_features.csv')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"3.Q_Mean_W2V.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
